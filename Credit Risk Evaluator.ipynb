{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Meet K Sahni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "#### In this notebook:\n",
    "\n",
    "1) 2019loans and 2020Q1Loans are read into dataframes. &emsp;\n",
    "2) After analyzing the columns and shape of dataframes, the training & testing datasets are broken into X (features) and y (label) values. &emsp;\n",
    "3) The training & test numeric data (X) is converted to categorical data using pd.get_dummies.&emsp;\n",
    "4) The y values (for both training & test datasets) are converted to numeric using LabelEncoder (since we do not want two different columns for labels)&emsp;\n",
    "5) Since the training & test datasets are not equal, the missing column(s) are found and inserted in test dataset.&emsp;\n",
    "6) Logistic Regression model is trained on the unscaled data and the model score is printed.\n",
    "7) Random Forest Classifier model is trained on the unscaled data and the model score is printed.&emsp;\n",
    "8) The scores of both the models are compared on unscaled data.&emsp;\n",
    "9) The training & testing data is then scaled using StandardScaler() function. &emsp;\n",
    "10) Both the models (Logical Regression & Random Forest Classifier) are re-applied to our training & testing datasets after they are scaled.&emsp;\n",
    "11) The scores are calculated and the code is concluded.&emsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0',\n",
       " 'acc_now_delinq',\n",
       " 'acc_open_past_24mths',\n",
       " 'all_util',\n",
       " 'annual_inc',\n",
       " 'application_type',\n",
       " 'avg_cur_bal',\n",
       " 'bc_open_to_buy',\n",
       " 'bc_util',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'collection_recovery_fee',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'debt_settlement_flag',\n",
       " 'delinq_2yrs',\n",
       " 'delinq_amnt',\n",
       " 'dti',\n",
       " 'hardship_flag',\n",
       " 'home_ownership',\n",
       " 'il_util',\n",
       " 'index',\n",
       " 'initial_list_status',\n",
       " 'inq_fi',\n",
       " 'inq_last_12m',\n",
       " 'inq_last_6mths',\n",
       " 'installment',\n",
       " 'int_rate',\n",
       " 'last_pymnt_amnt',\n",
       " 'loan_amnt',\n",
       " 'loan_status',\n",
       " 'max_bal_bc',\n",
       " 'mo_sin_old_il_acct',\n",
       " 'mo_sin_old_rev_tl_op',\n",
       " 'mo_sin_rcnt_rev_tl_op',\n",
       " 'mo_sin_rcnt_tl',\n",
       " 'mort_acc',\n",
       " 'mths_since_rcnt_il',\n",
       " 'mths_since_recent_bc',\n",
       " 'mths_since_recent_inq',\n",
       " 'num_accts_ever_120_pd',\n",
       " 'num_actv_bc_tl',\n",
       " 'num_actv_rev_tl',\n",
       " 'num_bc_sats',\n",
       " 'num_bc_tl',\n",
       " 'num_il_tl',\n",
       " 'num_op_rev_tl',\n",
       " 'num_rev_accts',\n",
       " 'num_rev_tl_bal_gt_0',\n",
       " 'num_sats',\n",
       " 'num_tl_120dpd_2m',\n",
       " 'num_tl_30dpd',\n",
       " 'num_tl_90g_dpd_24m',\n",
       " 'num_tl_op_past_12m',\n",
       " 'open_acc',\n",
       " 'open_acc_6m',\n",
       " 'open_act_il',\n",
       " 'open_il_12m',\n",
       " 'open_il_24m',\n",
       " 'open_rv_12m',\n",
       " 'open_rv_24m',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'pct_tl_nvr_dlq',\n",
       " 'percent_bc_gt_75',\n",
       " 'policy_code',\n",
       " 'pub_rec',\n",
       " 'pub_rec_bankruptcies',\n",
       " 'pymnt_plan',\n",
       " 'recoveries',\n",
       " 'revol_bal',\n",
       " 'tax_liens',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'tot_hi_cred_lim',\n",
       " 'total_acc',\n",
       " 'total_bal_ex_mort',\n",
       " 'total_bal_il',\n",
       " 'total_bc_limit',\n",
       " 'total_cu_tl',\n",
       " 'total_il_high_credit_limit',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'total_rec_prncp',\n",
       " 'total_rev_hi_lim',\n",
       " 'verification_status'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67991</td>\n",
       "      <td>67991</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>814.70</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>97.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>527975.0</td>\n",
       "      <td>70914.0</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>99475.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25429</td>\n",
       "      <td>25429</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>208.70</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34628.0</td>\n",
       "      <td>23460.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>23628.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38496</td>\n",
       "      <td>38496</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>128.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>19183.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19667</td>\n",
       "      <td>19667</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>478.33</td>\n",
       "      <td>RENT</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56481.0</td>\n",
       "      <td>43817.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>35981.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37505</td>\n",
       "      <td>37505</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>120.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45977.0</td>\n",
       "      <td>32448.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>24977.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  loan_amnt  int_rate  installment home_ownership  \\\n",
       "0       67991  67991    40000.0    0.0819       814.70       MORTGAGE   \n",
       "1       25429  25429     6000.0    0.1524       208.70           RENT   \n",
       "2       38496  38496     3600.0    0.1695       128.27           RENT   \n",
       "3       19667  19667    20000.0    0.1524       478.33           RENT   \n",
       "4       37505  37505     3600.0    0.1240       120.27           RENT   \n",
       "\n",
       "   annual_inc verification_status loan_status pymnt_plan  ...  pct_tl_nvr_dlq  \\\n",
       "0    140000.0        Not Verified    low_risk          n  ...            97.7   \n",
       "1     55000.0        Not Verified    low_risk          n  ...            66.7   \n",
       "2     42000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "3    100000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "4     50000.0        Not Verified    low_risk          n  ...           100.0   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0               0.0                   0.0        0.0         527975.0   \n",
       "1               0.0                   0.0        0.0          34628.0   \n",
       "2               0.0                   0.0        0.0          23100.0   \n",
       "3              50.0                   0.0        0.0          56481.0   \n",
       "4              25.0                   0.0        0.0          45977.0   \n",
       "\n",
       "   total_bal_ex_mort  total_bc_limit total_il_high_credit_limit  \\\n",
       "0            70914.0         74600.0                    99475.0   \n",
       "1            23460.0          5900.0                    23628.0   \n",
       "2            19183.0          7300.0                    15000.0   \n",
       "3            43817.0         13800.0                    35981.0   \n",
       "4            32448.0         21000.0                    24977.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag  \n",
       "0              N                     N  \n",
       "1              N                     N  \n",
       "2              N                     N  \n",
       "3              N                     N  \n",
       "4              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12180, 86)\n",
      "(4702, 86)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'loan_amnt', 'int_rate', 'installment',\n",
       "       'home_ownership', 'annual_inc', 'verification_status', 'loan_status',\n",
       "       'pymnt_plan', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc',\n",
       "       'pub_rec', 'revol_bal', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
       "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
       "       'collection_recovery_fee', 'last_pymnt_amnt',\n",
       "       'collections_12_mths_ex_med', 'policy_code', 'application_type',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
       "       'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
       "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
       "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
       "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
       "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
       "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
       "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
       "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
       "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
       "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
       "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
       "       'total_il_high_credit_limit', 'hardship_flag', 'debt_settlement_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical data to numeric and separate target feature for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_candidate1 = train_df[\"loan_status\"]  # define label\n",
    "X_candidate1 = train_df.drop(columns=[\"loan_status\"])  # drop label from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12180, 94)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols=[i for i in train_df.columns if i not in [\"loan_status\"]]\n",
    "#for col in cols:\n",
    "# One-hot encoding the X dataframe\n",
    "X_train = pd.get_dummies(X_candidate1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add LabelEncoder to y label in the training data\n",
    "y_train = LabelEncoder().fit_transform(y_candidate1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical data to numeric and separate target feature for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4702, 86)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_candidate2 = test_df[\"loan_status\"]  # define label\n",
    "X_candidate2 = test_df.drop(columns=[\"loan_status\"])  # drop label from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4702, 93)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding the X dataframe (test)\n",
    "X_test = pd.get_dummies(X_candidate2)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add LabelEncoder to y label in the training data\n",
    "y_test = LabelEncoder().fit_transform(y_candidate2)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debt_settlement_flag_Y'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add missing dummy variables to testing set\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "Column found\n",
      "debt_settlement_flag_Y\n"
     ]
    }
   ],
   "source": [
    "cols = X_train.columns\n",
    "for col in cols:\n",
    "    if col in X_test.columns:\n",
    "        print (\"Column found\")\n",
    "    else:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add missing column in test dataset\n",
    "X_test['debt_settlement_flag_Y'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4702, 94)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm if the column got added in X_test dataset\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=2000,solver = 'lbfgs')\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meetkamalkaursahni/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6982758620689655\n",
      "Testing Data Score: 0.5723096554657593\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seen above, the training & Testing Data Scores for Logical Regression Model on Unscaled Data are low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6180348787749894\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the other hand, the Training Data Scores for Random Forest Classfier Model on Unscaled Data are 100%. The testing data scores are not good but they are a little better than Logical Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7128899835796387\n",
      "Testing Data Score: 0.7201190982560612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After scaling the data, the Logical Regression Model scores improved considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6193109315185028\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, the Random Forest Model scores remain the same for unscaled & scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
